Statistics
==========
* **[21세기 통계학을 배우는 방법](http://statkclee.github.io/window-of-statistics/)**
* [통계는 숫자가 아니라 경험이 살린다](http://ppss.kr/archives/37791)
* [learnandrun.co.kr/category/learn-run/mathematics](http://learnandrun.co.kr/category/learn-run/mathematics)
* [pubdata.tistory.com/category/Lecture_Statistics](http://pubdata.tistory.com/category/Lecture_Statistics)
* [Sample your data!](http://www.chrisgoldammer.com/posts/sampling.html)
* [Understanding Variance, Co-Variance, and Correlation](http://www.countbayesie.com/blog/2015/2/21/variance-co-variance-and-correlation)
* [13 Great Articles and Tutorials about Correlation](http://www.datasciencecentral.com/profiles/blogs/13-great-articles-and-tutorials-about-correlation)
* [uniform random float](http://mumble.net/~campbell/2014/04/28/uniform-random-float)
* [A Decentralized Lie Detector](http://www.augur.net/blog/a-decentralized-lie-detector)
* [이정희 그리고 생일 역설](http://ppss.kr/archives/37856)
* [Expectation and Variance from High School to Grad School](http://www.countbayesie.com/blog/2015/3/19/expectation-and-variance-from-high-school-to-grad-school)
* [Kernel Density Estimation(커널밀도추정)에 대한 이해](http://darkpgmr.tistory.com/147)
* [The Price is Right Again](http://www.amstat.org/publications/jse/v20n2/burks.pdf)
* [Naive Bayesian, HMM, Maximum Entropy Model, CRF](https://github.com/dsindex/blog/wiki/%5Bstatistics%5D-Naive-Bayesian,-HMM,-Maximum-Entropy-Model,-CRF)
* [Engineering Statistics](http://www.itl.nist.gov/div898/handbook/index.htm)
* [bcho.tistory.com/category/빅데이타/통계학이론](http://bcho.tistory.com/category/%EB%B9%85%EB%8D%B0%EC%9D%B4%ED%83%80/%ED%86%B5%EA%B3%84%ED%95%99%20%EC%9D%B4%EB%A1%A0)
* P값; '영가설이 참이라고 가정할 때, 관찰된(또는 그보다 더 극단적인) 결과가 일어날 확률'로 정의
* [Statistics: P values are just the tip of the iceberg](http://www.nature.com/news/statistics-p-values-are-just-the-tip-of-the-iceberg-1.17412?WT.ec_id=NATURE-20150430)
* [p-value...  상관계수와 독립](https://brunch.co.kr/@headwaters/15)
* [P-value](http://terms.naver.com/entry.nhn?cid=58944&tkTocId=931470&categoryId=58970&tkListId=785221&docId=3580638&tkFrom=tlist&tkSort&mobile)
* [“p값 개선하자”…과학자들, 연구가설 검정 ‘문턱값’ 강화 제안](http://scienceon.hani.co.kr/540289)
* [미국 통계학회, P값의 오용(誤用)을 경고하는 성명서 발표](http://www.ibric.org/myboard/read.php?Board=news&id=270293)
* [Plot for distribution of common statistics and p-value](http://rpubs.com/cardiomoon/329065)
* [Why We Need a Statistical Revolution](http://www.stats.org/super-learning-and-the-revolution-in-knowledge/)
* [Mean Shift Clustering](http://spin.atomicobject.com/2015/05/26/mean-shift-clustering/)
* [Pattern Recognition](http://iskim3068.tistory.com/m/post?categoryId=473315)
* [The Extent and Consequences of P-Hacking in Science](http://journals.plos.org/plosbiology/article?id=10.1371/journal.pbio.1002106)
* [Exact computation of sums and means](https://radfordneal.wordpress.com/2015/05/21/exact-computation-of-sums-and-means/)
* [Why squared error?](http://www.benkuhn.net/squared)
* [How to lie with statistics](https://janav.wordpress.com/2014/01/03/how-to-lie-with-statistics/)
  * [통계로 거짓말 하는 방법](http://ppss.kr/archives/47334)
* [SERIAL CORRELATION IN TIME SERIES ANALYSIS](https://www.quantstart.com/articles/Serial-Correlation-in-Time-Series-Analysis)
* [정규분포](http://navercast.naver.com/contents.nhn?rid=22&contents_id=2490)
* [가우시안 분포(Gaussian Distribution) = 정규 분포(Normal Distribution)](https://nbviewer.jupyter.org/github/likejazz/likejazz.github.io/blob/master/public/notebooks/gaussian-distribution.ipynb)
* [Gaussian Distributions are Soap Bubbles](http://www.inference.vc/high-dimensional-gaussian-distributions-are-soap-bubble/)
* [Gaussian Processes](http://efavdb.com/gaussian-processes/)
* **[Industrial Gaussian Process Regression Introduction - 본 자료는 ICMLA Tutorial로 진행된 Gaussian Process Regression 내용을 정리](https://github.com/LeeDoYup/ML_Implementations/blob/master/GP/1_GP_basics_KOR.ipynb)**
* [Evaluating Splatoon's Ranking System](http://www.evanmiller.org/evaluating-splatoons-ranking-system.html)
* [Understanding the t-distribution and its normal approximation](http://rpsychologist.com/d3/tdist/)
* [Statistics for Hackers by Jake VanderPlas](https://speakerdeck.com/jakevdp/statistics-for-hackers)
* [Frequentism and Bayesianism: A Python-driven Primer](http://arxiv.org/abs/1411.5018)
* [Probability, Mathematical Statistics, Stochastic Processes](http://www.math.uah.edu/stat/)
* [A Simple Introduction to Complex Stochastic Processes](https://www.datasciencecentral.com/profiles/blogs/a-simple-introduction-to-complex-stochastic-processes)
* [Probabilistic algorithms for fun and pseudorandom profit](http://www.slideshare.net/TylerTreat/probabilistic-algorithms-for-fun-and-pseudorandom-profit)
* [인지모델링 - 수리심리학 + 베이지안 인지모델링 + IT 모델링](http://psygrammer.github.io/coco/)
* [자유도의 의미](http://blog.naver.com/hancury/220625928193)
* [The Automatic Statistician - An artificial intelligence for data science](http://www.automaticstatistician.com/examples/)
* [Common Probability Distributions: The Data Scientist’s Crib Sheet](https://blog.cloudera.com/blog/2015/12/common-probability-distributions-the-data-scientists-crib-sheet/)
  * 데이터 사이언스에 많이 사용되는 확률밀도함수들
    * Bernoulli
      * 동전의 앞/뒤처럼 이벤트가 0 또는 1밖에 일어나지 않는 분포
      * 동전은 확률이 0.5/0.5 겠지만 다른 경우도 있을 수 있음
    * Uniform
      * 주사위처럼 모든 결과에 대한 확률이 동일한 확률분포
    * Binomial
      * 동전을 n번 던졌을 때 p번만큼 앞면이 나올 확률은?
      * Binomial은 이렇게 0 또는 1이 나오는 이벤트(각각이 Bernoulli확률을 갖는 이벤트)에 대해 1이 발생활 횟수에 대한 확률
    * Poisson
      * 1시간에 평균 10번의 전화통화가 온다고 가정. 그렇다면 한시간에 12번 전화통화가 올 확률은? 이것이 바로 poisson(포아송) 확률
      * 이것은, 예를 들어, 60분 중 48번의 실패(0)와 12번의 성공(1)을 하면 ok. 또는, 60분이 아니라 더 잘게 쪼개서 988번의 실패와 12번의 성공을 하면 ok
      * 이처럼 시행횟수가 크고 이벤트가 일어날 확률이 작은 bionomial 분포가 바로 poisson 분포에 수렴(이 때문에 binomial의 근사로도 사용)
    * Hypergeometric
      * 까만공과 하얀공이 절반씩 있는데 그것을 여러번 뽑는다고 가정. 그럼 이것은 Binomial과 동일한가?
      * 아님. 왜냐면 공을 뽑을 때 만약 그 공을 다시 채워넣지 않는다면 남아있는 공의 확률은 바뀌기 때문
      * Binomial의 경우와 달리 replacement(다시 보충)를 허용하지 않는 것이 바로 hypergeometric 확률입니다.
    * Geometric
      * 주사위를 굴렸을 때 한번에 6이 나올 확률은? 두번만에 6이 나올 확률은? 세번만에, 네번만에...
      * 이처럼 geometric 분포는 어떤 이벤트가 일어날 때까지의 횟수에 대한 확률
      * 이벤트의 확률이 어떠하든 늘 "가장 첫번째"에 이벤트가 발생할 확률이 가장 크다
    * Negative Binomial
      * Geometric이 한번 성공할 때까지 걸리는 횟수에 대한 분포라면 negative binominal은 n번 성공할 때까지 걸리는 횟수에 대한 분포
비슷하게 안지은거야?;;)
    * Exponential
      * bionomial의 연속버전이 poisson이었다면, geometric의 연속버전이 exponential분포
      * 다시말해 "평균 5분만에 전화가 걸려온다고 할 때 다음 전화가 7분 후에 걸려올 확률은?"
    * Weibull
      * exponential이 "다음 이벤트가 성공할 때 까지의 실패구간은"에 대한 함수였다면 반대로 Weibull은 "첫 실패가 발생할 때까지 이번 이벤트가 성공할 구간"에 대한 확률
    * Gaussian (Normal)
      * 너무 유명한 확률분포
      * 특히 매우 많은 수의 동일 확률분포를 가진 샘플들의 산술평균은 그 샘플들이 어떤 분포를 따르든(binomial이든 exponential이든 아님 다른거든) 결국 Gaussian 분포로 수렴한다는 "중심극한정리"가 매우 유용하기에 매우 많은 곳에 적용 가능
    * Log-normal
      * 변수의 log 값이 Gaussian을 나타내는 분포
      * 다시말해 Gaussian을 exponential 한 함수
    * Student’s t-distribution
      * 정규분포의 mean 값에 대한 판단을 내릴 떄 사용하는 확률분포
    * Chi-squared distribution
      * Gaussian 분포를 가진 확률변수의 제곱들의 합에 대한 분포
      * 예를 들어 k자유도의 chi-squared는 k개의 독립적인 Gaussian들에 대한 합의 확률분포
* [Statistical Methods for HCI Research](http://yatani.jp/teaching/doku.php?id=hcistats:start)
* [Statistics for everyone](http://statistics4everyone.blogspot.com/2016/05/p-story-i.html)
* [변동계수](https://ko.m.wikipedia.org/wiki/%EB%B3%80%EB%8F%99%EA%B3%84%EC%88%98) 평균 + 분산값 통합 평가
* [통계학 입문 수준의 공부방법 및 추천 서적](http://posterior.egloos.com/m/9637423)
* [피셔정확검정을 통한 고객군 상품구매액평균 순위 분석](http://blog.naver.com/hancury/220797689533)
* [math7.tistory.com/m/category/통계](http://math7.tistory.com/m/category/%ED%86%B5%EA%B3%84)
* [Three common misuses of P values](http://www.dentalhypotheses.com/article.asp?issn=2155-8213;year=2016;volume=7;issue=3;spage=73;epage=80;aulast=Kim)
* [LEARNING STATISTICS ON YOUTUBE](http://flavioazevedo.com/stats-and-r-blog/2016/9/13/learning-r-on-youtube)
* [만화로 쉽게 보는 통계분석 - 확률의 공리 편 -](http://cafe.daum.net/Statistics.sniper)
* [딥러닝 예제로 보는 개발자를 위한 통계 최재걸](http://www.slideshare.net/deview/216-67609104)
* [층화 추출(stratified sampling)](http://blog.naver.com/PostView.nhn?blogId=gusdud9104&logNo=90084128175)
  * qc 기준으로 층화 샘플링 하는 경우
    * (query, query count) pair 생성 후 qc로 sort
    * n개 구간으로 분리 후, k개씩 random choice
    * 구간의 전체 개수가 k보다 작은 경우
      * 추출 기간 증가
      * 구간 개수 축소
* [정확한 처리 효과 분석을 위한 성향점수분석(PSA)](http://freesearch.pe.kr/archives/4377)
* [STAT 501](https://onlinecourses.science.psu.edu/stat501/)
* [statground.org](http://www.statground.org/) 수리통계학 pdf 자료 받은 곳
* [R Codes for "허명회 (2001), <수리통계학 강의>"](https://github.com/praster1/MathematicalStatistics)
* 아빠가 들려주는 통계
  * [자료 정리의 중요성](http://blog.naver.com/kjhnav/221044778964)
  * [엑셀 자료 정리 팁](http://blog.naver.com/kjhnav/221025023797)
  * [P값의 이해와 샘플 수 계산의 이해](http://blog.naver.com/kjhnav/220915201622)
  * [chi-square goodness of fit test 카이제곱 적합도 검정](http://blog.naver.com/kjhnav/220939776135)
  * [다중 검정의 위험: 회귀분석의 예에서](http://blog.naver.com/kjhnav/220958669369)
  * [Prediction Model & NIR, cfNIR, IDI](http://blog.naver.com/kjhnav/220990628798)
  * [Cox-Stuart test for trend](http://blog.naver.com/kjhnav/221004222425)
  * [Curve fitting 추세선 편집](http://blog.naver.com/kjhnav/221006027832)
  * [Heat Map의 대안들](http://blog.naver.com/kjhnav/221006351901)
  * [데이터 시각화 dot bar chart](http://blog.naver.com/kjhnav/221009856973)
  * [무작위 추출 연습](http://blog.naver.com/kjhnav/221012172204)
  * [step line chart 계단 차트](http://blog.naver.com/kjhnav/221013234461)
  * [brick chart 벽돌 차트](http://blog.naver.com/kjhnav/221013536421)
  * [예측하기](http://blog.naver.com/kjhnav/221015331524)
  * [brick chart 2](http://blog.naver.com/kjhnav/221035264782)
  * [파이차트 선버스트 도넛차트](http://blog.naver.com/kjhnav/221040480056)
  * [제주 공항 승객수 예측](http://blog.naver.com/kjhnav/221108118837)
  * [dot violin boxplot](http://blog.naver.com/kjhnav/221145918388)
  * [densitogram](http://blog.naver.com/kjhnav/221145999631)
* [Common Probability Distributions: The Data Scientist’s Crib Sheet](http://www.datasciencecentral.com/profiles/blogs/common-probability-distributions-the-data-scientist-s-crib-sheet)
* [보이지 않는 총알 자국 - 남들을 뛰어넘는 생각의 차이(아브라함 발드)](http://blog.naver.com/shc427118/220944502924)
* [www.medicine.mcgill.ca/epidemiology/hanley/software](http://www.medicine.mcgill.ca/epidemiology/hanley/software/)
* [seeing theory](http://students.brown.edu/seeing-theory/)
* [조건부 확률 문제](https://gist.github.com/hyunjun/248eb9072f307ab4109f2b872674708b)
* [Why Mean Squared Error and L2 regularization? A probabilistic justification](http://aoliver.org/why-mse)
  * 데이터가 zero mean Gaussian 분포를 띌때, maximizing probability의 과정에서 L2 loss function(MSE)이 유도될 수 있음
  * 또한 L2 regularization도 도출 가능
  * 데이터가 라플라스 분포를 띌때는 L1 loss function 및 L1 regularization을 얻을 수 있음
* Agreement, Reliability를 보는 Krippendorff’s alpha
  * [Krippendorff's alpha](https://en.wikipedia.org/wiki/Krippendorff%27s_alpha)
  * [ReCal for Ordinal, Interval, and Ratio Data (OIR)](http://dfreelon.org/utils/recalfront/recal-oir/)
* [통계학에서의 추정법](http://basicstatistics.tistory.com/entry/%ED%86%B5%EA%B3%84%ED%95%99%EC%97%90%EC%84%9C%EC%9D%98-%EC%B6%94%EC%A0%95%EB%B2%95)
* [So You Think You Can Stats](http://nadbordrozd.github.io/blog/2017/07/18/so-you-think-you-can-stats/)
* [평균, 표준편차, 표준정규분포의 이해와 활용](http://ohgyun.com/745)
* [독립사건 (independent event), 종속사건 (dependent event), 조건부 확률(conditional probability), 결합 확률 (joint probability)](https://www.facebook.com/terryum/posts/10155583605654417)
* [지나치게 자세한 수리통계(원)](http://blog.naver.com/kwonpub/221079139699)
* [Frequency diagrams: A first look at Bayes](https://arbital.com/p/bayes_frequency_diagram/?l=55z&pathId=22608)
* [통계에 사용되는 기초 공식들](http://blog.naver.com/kjhnav/221097570909)
* [CHOOSING THE CORRECT STATISTICAL TEST IN SAS, STATA, SPSS AND R](https://stats.idre.ucla.edu/other/mult-pkg/whatstat/)
* [확률변수 함수의 분포를 알아보자 - Delta method에 대하여 (1)](http://issactoast.com/133)
* [Propensity Score Matching (PSM) 기법 요약](http://blog.naver.com/hancury/221091701744)
* [모수적 방법과 비모수적 방법](http://dermabae.tistory.com/147)
* [Statistical Rethinking - Lecture 01](https://speakerdeck.com/rmcelreath/statistical-rethinking-lecture-01)
* [Fair and Balanced? Thoughts on Bias in Probabilistic Modeling](https://medium.com/@cody.marie.wild/fair-and-balanced-thoughts-on-bias-in-probabilistic-modeling-2ffdbd8a880f)
* [The 10 Statistical Techniques Data Scientists Need to Master](https://towardsdatascience.com/the-10-statistical-techniques-data-scientists-need-to-master-1ef6dbd531f7)

# Bayes
* [쉽게 이해하는 베이즈 정리](http://blog.naver.com/anthouse28/221077405435)
* [베이지언 확률](http://darkpgmr.tistory.com/119)
* **[베이시안 통계 첫걸음!](https://medium.com/@deepvalidation/%EB%B2%A0%EC%9D%B4%EC%8B%9C%EC%95%88-%ED%86%B5%EA%B3%84-%EC%B2%AB%EA%B1%B8%EC%9D%8C-7e7e1a5f5adc)**
* [베이시안 통계 둘째 걸음!](https://medium.com/@deepvalidation/%EB%B2%A0%EC%9D%B4%EC%8B%9C%EC%95%88-%ED%86%B5%EA%B3%84-%EB%91%98%EC%A7%B8-%EA%B1%B8%EC%9D%8C-b486aa23d68b)
  * [github.com/Minsu-Daniel-Kim/bayesian_secon_step](https://github.com/Minsu-Daniel-Kim/bayesian_secon_step)
* [베이지안 추론 - 1편](https://brunch.co.kr/@chris-song/59)
* [Intro to Bayes stat](http://posterior.egloos.com/9602501) 베이지안 통계학 입문서 및 절차, 도구 소개
* [Bayes 101](https://www.facebook.com/pg/SKTBrain/photos/?tab=album&album_id=337638653273622)
* [Bayesian Statistics explained to Beginners in Simple English](http://www.analyticsvidhya.com/blog/2016/06/bayesian-statistics-beginners-simple-english)
* [The Bayesian Trap](https://www.youtube.com/watch?v=R13BD8qKeTg)
* [www.countbayesie.com](http://www.countbayesie.com)
  * [Bayes' Theorem with Lego](http://www.countbayesie.com/blog/2015/2/18/bayes-theorem-with-lego)
  * [Building a Voight-Kampff Test with Bayes Factor](http://www.countbayesie.com/blog/2015/2/27/building-a-bayesian-voight-kampff-test)
  * [A Guide to Bayesian Statistics](https://www.countbayesie.com/blog/2016/5/1/a-guide-to-bayesian-statistics)
* [The Bayesian Case Model: A Generative Approach for Case-Based Reasoning and Prototype Classification](http://papers.nips.cc/paper/5313-the-bayesian-case-model-a-generative-approach-for-case-based-reasoning-and-prototype-classification)
* [Bayes’ Theorem, Predictions and Confidence Intervals](http://kukuruku.co/hub/algorithms/bayes-theorem-predictions-and-confidence-intervals)
* [Bayesian truth serum](http://nel.mit.edu/bayesian-truth-serum)
* [Kalman and Bayesian Filters in Python](http://nbviewer.ipython.org/github/rlabbe/Kalman-and-Bayesian-Filters-in-Python/blob/master/table_of_contents.ipynb)
  * [Kalman Filter textbook using Ipython Notebook. Focuses on building intuition and experience, not formal proofs. Includes Kalman filters,extended Kalman filters, unscented Kalman filters, particle filters, and more. All exercises include solutions](https://github.com/rlabbe/Kalman-and-Bayesian-Filters-in-Python)
  * [Kalman and Bayesian Filters in Python](https://drive.google.com/file/d/0By_SW19c1BfhSVFzNHc0SjduNzg/view)
  * [How a Kalman filter works, in pictures](http://www.bzarg.com/p/how-a-kalman-filter-works-in-pictures/)
  * [칼만 필터를 이용하여 위치에서 속도를 구하는 예제](http://pinkwink.kr/781)
* [FilterPy - a Python library that implements a number of Bayesian filters, most notably Kalman filters](http://filterpy.readthedocs.io/)
* [공학자를 위한 Python 사용법 25 - Quaternion을 이용한 자세 추정 칼만 필터](http://myjr52.tumblr.com/post/128707132156/%EA%B3%B5%ED%95%99%EC%9E%90%EB%A5%BC-%EC%9C%84%ED%95%9C-python-%EC%82%AC%EC%9A%A9%EB%B2%95-25)
* [Using naive bayes to predict movie review sentiment](http://blog.dataquest.io/blog/naive-bayes-movies/)
* [Continuous Bayes](http://www.sidhantgodiwala.com/blog/2015/03/14/continuous-bayes/)
* [A Case Study in Empirical Bayes](http://www.ebaytechblog.com/2015/02/06/a-case-study-in-empirical-bayes/)
* [BAYESIAN STATISTICS AS A WAY TO INTEGRATE INTUITION AND DATA](https://keen.io/blog/98491909836/bayesian-statistics-as-a-way-to-integrate-intuition-and)
* [나이브 베이즈 분류 (Naive Bayesian classification) #1 - 소개](http://bcho.tistory.com/1010)
* [베이지안 네트워크](http://newsight.tistory.com/158)
* [Think Bayes](http://allendowney.blogspot.kr/)
  * [Chapter 02. Introduction : Credibility, Models, and Parameters](https://github.com/psygrammer/bayesianR/blob/master/part1/ch01_02/ch01_02_intro.md)
* [Proper postulates](http://posterior.egloos.com/category/Intro%20to%20Bayes%20stat/page/2)
  * [베이즈 정리](http://posterior.egloos.com/9604153)
  * [주관적 확률의 사용과 그 경험과학적 의미](http://posterior.egloos.com/9603023)
* [Probabilistic Programming and Bayesian Methods for Hackers](https://github.com/CamDavidsonPilon/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers/blob/master/Chapter1_Introduction/Chapter1.ipynb)
* [An intro to Bayesian methods and probabilistic programming from a computation/understanding-first, mathematics-second point of view](http://camdavidsonpilon.github.io/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers/#contents)
* [BAYESIAN INFERENCE OF A BINOMIAL PROPORTION - THE ANALYTICAL APPROACH](http://www.quantstart.com/articles/Bayesian-Inference-of-a-Binomial-Proportion-The-Analytical-Approach)
* [집단지성프로그래밍 ch6. 문서 필터링](http://www.slideshare.net/icristi/ch6-48743141)
* [An Intuitive Explanation of Bayes' Theorem](http://www.yudkowsky.net/rational/bayes)
* [Probabilistic Programming & Bayesian Methods for Hackers](http://camdavidsonpilon.github.io/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers/)
* [메르스 바로 알기: 양성일 때 메르스 환자일 확률은 얼마나 될까?](http://ppss.kr/archives/49107)
* [베이지언이 되자~!](http://pgr21.com/?b=8&n=59237)
* [Bayes’ Theorem](http://crucialconsiderations.org/rationality/bayes-theorem/)
* [A Tutorial on Learning With Bayesian Networks](http://research.microsoft.com/pubs/69588/tr-95-06.pdf)
* [Basic MCMC and Bayesian statistics in... BASIC!](http://sumsar.net/blog/2015/08/basic-mcmc-and-bayesian-statistics-in-basic/)
* [MCMC sampling for dummies](http://twiecki.github.io/blog/2015/11/10/mcmc-sampling/)
  * [쉽게 쓰여진 MCMC](http://blog.naver.com/rupy400/220775812498)
* [Importance sampling 방법](http://blog.naver.com/kwonpub/221143316307])
* [Bayesian과 MCMC 알고리즘 (Gibbs and Metropolis-Hastings Algorithm)](http://enginius.tistory.com/m/514)
* [Bayesian Financial Models](http://toddmoses.com/articles/read/bayesian_financial_models)
* [Bayesian Cookies](http://www.sidhantgodiwala.com/blog/2015/07/12/bayesian-cookies/)
* [In praise of Bayes](http://www.cs.ubc.ca/~murphyk/Bayes/economist.html)
* [A Brief Introduction to Graphical Models and Bayesian Networks](http://www.cs.ubc.ca/~murphyk/Bayes/bnintro.html)
* [Bayesian democracy](https://samgentle.com/posts/2015-08-28-bayesian-democracy)
* [The Bayesian Reproducibility Project](http://alexanderetz.com/2015/08/30/the-bayesian-reproducibility-project/)
* [Using Bayes Factors to Get the Most out of Linear Regression: A Practical Guide Using R](https://thewinnower.com/papers/278-using-bayes-factors-to-get-the-most-out-of-linear-regression-a-practical-guide-using-r)
* [베이즈 이론이 푸리에 정리를 만났을 때](https://brunch.co.kr/@cojette/1)
* [Naive Bayesian Classification(나이브 베이즈 분류)](http://unlimitedpower.tistory.com/entry/NLP-Naive-Bayesian-Classification%EB%82%98%EC%9D%B4%EB%B8%8C-%EB%B2%A0%EC%9D%B4%EC%A6%88-%EB%B6%84%EB%A5%98)
* [Bayes Theorem and Naive Bayes](http://alexhwoods.com/2015/11/08/bayes-theorem-and-naive-bayes/)
* [SigOpt for ML: Unsupervised Learning with Even Less Supervision Using Bayesian Optimization](http://blog.sigopt.com/post/140871698423/sigopt-for-ml-unsupervised-learning-with-even)
* [bayes.js - MCMC and Bayes in the browser](https://github.com/rasmusab/bayes.js)
* [Human-level concept learning through probabilistic program induction Bayesian Program Learning (BPL) model for one-shot learning](http://gitxiv.com/posts/jS9LJ5kh9ny6iqD7Z/human-level-concept-learning-through-probabilistic-program)
* [Bayesian reasoning implicated in some mental disorders](https://www.sciencenews.org/article/bayesian-reasoning-implicated-some-mental-disorders)
* [Bayesian Deep Learning](http://twiecki.github.io/blog/2016/06/01/bayesian-deep-learning/)
* [Bayesian Machine Learning, Explained](http://www.rightrelevance.com/search/articles/hero?article=5f8cc010177776a7f4d48089ec4e539dc42a1ff9)
* [어떻게 하면 싱싱한 데이터를 모형에 바로 적용할 수 있을까? – Bayesian Online Leaning](http://freesearch.pe.kr/archives/4497)
* [Conditional probability explained visually (Bayes Theorem formula)](https://www.youtube.com/watch?v=Zxm4Xxvzohk&feature=youtu.be)
* [Bayesian Machine Learning, Explained](http://www.kdnuggets.com/2016/07/bayesian-machine-learning-explained.html)
* [Machine learning - Bayesian optimization and multi-armed bandits](https://www.youtube.com/watch?v=vz3D36VXefI&t=1786s)
* [How Bayesian inference works](https://www.youtube.com/watch?v=5NMxiOGL39M)
* [A visual guide to Bayesian thinking](https://www.youtube.com/watch?v=BrK7X_XlGB8)
* [Introduction to Bayesian Statistics, part 1: The basic concepts](https://www.youtube.com/watch?v=0F0QoMCSKJ4)
* [Introduction to Bayesian Statistics, part 2: MCMC and the Metropolis Hastings algorithm](https://www.youtube.com/watch?v=OTO1DygELpY)
* [Learning to Love Bayesian Statistics](https://www.youtube.com/watch?v=R6d-AbkhBQ8)
* [Bayesian statistics made (as) simple (as possible)](https://www.youtube.com/watch?v=bobeo5kFz1g)
* [Bayesian statistics syllabus](https://www.youtube.com/watch?v=U1HbB0ATZ_A&list=PLFDbGp5YzjqXQ4oE4w9GVWdiokWB9gEpm)
* [Bayesian Deep Learning NIPS 2016 Workshop](http://bayesiandeeplearning.org/#schedule)
* [bayesian_linear_regression.ipynb](https://github.com/liviu-/notebooks/blob/master/bayesian_linear_regression.ipynb)
* **[시뮬레이션이 다해주실거야](http://mathpsych.tumblr.com/post/155015433099/%EC%8B%9C%EB%AE%AC%EB%A0%88%EC%9D%B4%EC%85%98%EC%9D%B4-%EB%8B%A4%ED%95%B4%EC%A3%BC%EC%8B%A4%EA%B1%B0%EC%95%BC)**
* [베이지안통계](http://mathpsych.tumblr.com/post/155014009869/%EB%B2%A0%EC%9D%B4%EC%A7%80%EC%95%88%ED%86%B5%EA%B3%84)
* [Stan을 이용한 베이지안 회귀분석](http://mathpsych.tumblr.com/post/155094553934/stan%EC%9D%84-%EC%9D%B4%EC%9A%A9%ED%95%9C-%EB%B2%A0%EC%9D%B4%EC%A7%80%EC%95%88-%ED%9A%8C%EA%B7%80%EB%B6%84%EC%84%9D)
* [Bayesian Deep Learning and Black Box Variational Inference](https://www.youtube.com/watch?v=cbC1M02BO8I&spfreload=10)
* [The Power and Danger of Bayes’ Theorem](http://strangenotions.com/the-power-and-danger-of-bayes-theorem/)
* **[How To Build a Simple Spam-Detecting Machine Learning Classifier](https://hackernoon.com/how-to-build-a-simple-spam-detecting-machine-learning-classifier-4471fe6b816e)**
* [Bayesian Statistics Course Overview.ipynb](https://github.com/KaggleBreak/analyticstool/blob/master/part4/Bayesian/review/Bayesian%20Statistics%20Course%20Overview.ipynb)
* [Thomas Huijskens - Bayesian optimisation with scikit-learn](https://www.youtube.com/watch?v=jtRPxRnOXnk)
* [Bayesian Nonparametric Models](https://www.datasciencecentral.com/profiles/blogs/6448529:BlogPost:635167)
* [Introduction to Bayesian Thinking: from Bayes theorem to Bayes networks](https://towardsdatascience.com/will-you-become-a-zombie-if-a-99-accuracy-test-result-positive-3da371f5134)
* [Conditional probability explained visually (Bayes' Theorem)](https://www.youtube.com/watch?v=Zxm4Xxvzohk)
* [Statistical Computing for Scientists and Engineers](https://www.zabaras.com/statisticalcomputing)
* [Monty Hall & Bayes Thm](http://rpubs.com/foxeyboy/346435)
* Probability concepts explained
  * [Introduction](https://towardsdatascience.com/probability-concepts-explained-introduction-a7c0316de465)
  * [Maximum likelihood estimation](https://towardsdatascience.com/probability-concepts-explained-maximum-likelihood-estimation-c7b4342fdbb1)
  * [Bayesian inference for parameter estimation](https://towardsdatascience.com/probability-concepts-explained-bayesian-inference-for-parameter-estimation-90e8930e5348)
* [Underestimating Estimation](https://hackernoon.com/underestimating-estimation-d2e52372f303)
* [Chapter2: Likelihood-based approach](https://www.slideshare.net/JaekwangKim5/chapter2-likelihoodbased-approach)
* [Bayes’ Rule Applied - Using Bayesian Inference on a real-world problem](https://towardsdatascience.com/bayes-rule-applied-75965e4482ff)

# Book
* [기초부터 응용까지 무료 통계학 eBook 19선 + α](http://wsyang.com/2013/08/free-ebooks-for-statistics/)
* [An Adventure in STATISTICS](http://discoveringstatistics.blogspot.com/2016/04/if-youre-not-doing-something-different.html)
* [An Introduction to Statistical Learning with Applications in R](http://www-bcf.usc.edu/~gareth/ISL/)
  * **[github.com/hyunblee/ISLR-with-Python](https://github.com/hyunblee/ISLR-with-Python)** Introduction to Statistical Learning in R (ISLR)을 Python으로
    * [K-Nearest Neighbors Regression/Classification & Model Evaluations](http://nbviewer.jupyter.org/github/hyunblee/ISLR-with-Python/blob/master/Ch4-Classification/Ch4_KNN_Reg_Clf_n_Evaluation.ipynb)
* [Understanding The New Statistics: Effect Sizes, Confidence Intervals, and Meta-Analysis (Multivariate Applications Series)](https://www.amazon.com/Understanding-New-Statistics-Meta-Analysis-Multivariate/dp/041587968X)
* [Introduction to the New Statistics: Estimation, Open Science, and Beyond](https://www.amazon.com/Introduction-New-Statistics-Estimation-Science/dp/1138825522/)
* [Think Stats 2e](http://greenteapress.com/wp/think-stats-2e/) python + statistics, free download
* [Computer Age Statistical Inference: Algorithms, Evidence and Data Science](https://web.stanford.edu/~hastie/CASI/)
* [project mosaic book](http://project-mosaic-books.com/) Computer-savvy textbooks on statistics and data science

# Haskell
* [A gentle introduction to statistical relational learning: maths, code, and examples](http://phdp.github.io/posts/2015-07-13-srl-code.html)

# Library
* [Javascript library for the visualization of statistical distributions](https://github.com/richarddmorey/stat-distributions-js)
* [Stan is a probabilistic programming language implementing full Bayesian statistical inference](http://mc-stan.org/)
  * [StanCon Contributed Talks](https://github.com/stan-dev/stancon_talks)
  * [StanCon 2018 - Intro Stan Class Materials](http://mc-stan.org/workshops/stancon2018_intro/)
  * [Stan Conference 2017](https://www.youtube.com/watch?v=DJ0c7Bm5Djk)

# Poisson Distribution
* [Understanding Waiting Times Between Events with the Poisson and Exponential Distributions](http://nbviewer.ipython.org/github/nicolewhite/notebooks/blob/master/Poisson.ipynb)

# Probability
* [Probability Cheatsheet](http://www.wzchen.com/probability-cheatsheet)
* [Foundations of probability theory](https://terrytao.wordpress.com/2015/09/29/275a-notes-0-foundations-of-probability-theory/)
* [Heuristic models for marginal probability assessment updates](http://xheimlichkeit.com/methods/2015/10/12/how-to-update-probabilities.html)
* [Probability concepts explained: Marginalisation](https://towardsdatascience.com/probability-concepts-explained-marginalisation-2296846344fc)

# Python
* [How To Implement These 5 Powerful Probability Distributions In Python](http://hpc-asia.com/how-to-implement-these-5-powerful-probability-distributions-in-python/)
* [An Introduction to Statistics with Python](http://work.thaslwanter.at/Stats/html/)
* [PyMC: Bayesian Stochastic Modelling in Python http://pymc-devs.github.com/pymc/](https://github.com/pymc-devs/pymc)
  * [Probabilistic Programming & Bayesian Methods for Hackers](http://camdavidsonpilon.github.io/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers/)
  * [A/B Testing with Hierarchical Models in Python](http://blog.dominodatalab.com/ab-testing-with-hierarchical-models-in-python/)
  * [Bayesian Methods for Hackers - Using Python and PyMC](https://github.com/CamDavidsonPilon/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers)
  * [Torsten Scholak, Diego Maniloff Intro to Bayesian Machine Learning with PyMC3 and Edward](https://www.youtube.com/watch?v=fR5Wvb86-IU)
  * [Christopher Fonnesbeck Probabilistic Programming with PyMC3 PyCon 2017](https://www.youtube.com/watch?v=5TyvJ6jXHYE)
  * [Markov Chain Monte Carlo in Python - A Complete Real-World Implementation](https://towardsdatascience.com/markov-chain-monte-carlo-in-python-44f7e609be98)
* [Computational Statistics in Python](http://people.duke.edu/~ccc14/sta-663/index.html)
* [bayesianPy](http://psygrammer.github.io/bayesianPy/)
* [pomegranate is a package for graphical models and Bayesian statistics for Python, implemented in cython](https://github.com/jmschrei/pomegranate)
* [통계적 사고: 파이썬을 이용한 탐색적 자료 분석](http://think-stat.xwmooc.org/)
* [ThinkBayes (IPython notebook included)](https://github.com/rlabbe/ThinkBayes)
* [Fitting Multivariate Normal Distributions](https://waterprogramming.wordpress.com/category/programming/python/)
* [파이썬 확률과 통계 기초 이해하기](http://www.slideshare.net/dahlmoon/lambda-20160315)
* [ISLR-python](https://github.com/JWarmenhoven/ISLR-python)
* [Eric J Ma Bayesian Statistical Analysis with Python PyCon 2017](https://www.youtube.com/watch?v=p1IB4zWq9C8)
* [pomegranate - Fast, flexible and easy to use probabilistic modelling in Python](https://github.com/jmschrei/pomegranate)
  * 확률분포, GMM, HMM, Naive Bayes, Bayes Classifiers, Markov Chains 등을 지원
* [Christine Waigl The Next Step Finding Model Parameters With Random Walks PyCon 2017](https://www.youtube.com/watch?v=sHS2-av7AgQ)
* **[Python For Sport Scientists: Descriptive Statistics](https://towardsdatascience.com/python-for-sport-scientists-descriptive-statistics-96ed7e66ab3c)** 기초 내용 설명

# R
* [bayesianR](http://psygrammer.github.io/bayesianR/)
