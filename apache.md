Apache
======
* [apache bigdata europe](http://events.linuxfoundation.org/events/apache-big-data-europe/program/schedule)
* [Apache 프로젝트 만들기(1)](http://www.popit.kr/apache-%ED%94%84%EB%A1%9C%EC%A0%9D%ED%8A%B8-%EB%A7%8C%EB%93%A4%EA%B8%B0-1/)
* [Apache 프로젝트 만들기(2)](http://www.popit.kr/apache-%ED%94%84%EB%A1%9C%EC%A0%9D%ED%8A%B8-%EB%A7%8C%EB%93%A4%EA%B8%B02/)
* [Projects by category](https://projects.apache.org/projects.html?category)

# Airflow
* [Integrating Apache Airflow and Databricks: Building ETL pipelines with Apache Spark](https://databricks.com/blog/2016/12/08/integrating-apache-airflow-databricks-building-etl-pipelines-apache-spark.html)
  * Apache Airflow에서 REST API를 사용하여 Databricks 클러스터를 관리하는 예를 소개
* [데이타 워크플로우 관리를 위한 Apache Airflow #1 - 소개](http://bcho.tistory.com/1184)
* [Airflow Tutorial for Data Pipelines](https://blog.godatadriven.com/practical-airflow-tutorial)
  * Apache Airflow를 시작할 때 참고할만한 튜토리얼
* **[Apache Airflow를 이용한 데이터 워크플로우 자동화](http://whitechoi.tistory.com/50)**
* [ETL best practices with Airflow documentation site](https://gtoonstra.github.io/etl-with-airflow/)

# Ambari
* [3 GREAT REASONS TO TRY APACHE HIVE VIEW 2.0](https://hortonworks.com/blog/3-great-reasons-to-try-hive-view-2-0/)
  * Apache Ambari에서 Apache Hive 2.5와 상호 작용할 수 잇는 새로운 기능을 소개
  * Optimizer가 사용하는 테이블과 컬럼 통계를 보고 연산 가능, Explain pland 시각화 포함
* [WHY SHOULD YOU CARE ABOUT AMBARI 2.5?](https://hortonworks.com/blog/ambari-2-5/)
  * Apache Ampari 2.5 공개. 서비스 자동 재시작, 로그 로테이션/로그 검색, 개선된 구성 관리와 새로운 모니터링 기능 등이 포함

# [Apex](http://apex.apache.org/) 스트림 및 배치 프로세스 엔진
* [Real-time Stream Processing using Apache Apex](http://www.slideshare.net/ApacheApex/realtime-stream-processing-using-apache-apex)
* [Throughput, Latency, and Yahoo! Performance Benchmarks. Is there a winner? - See more at: https://www.datatorrent.com/blog/throughput-latency-and-yahoo](https://www.datatorrent.com/blog/throughput-latency-and-yahoo/)
* [SQL on Apache Apex](https://www.datatorrent.com/blog/sql-apache-apex)
* [Writing to Apache Kudu from Apache Apex](http://www.atrato.io/blog/2017/05/28/apex-kudu-output/)
  * Apache Apex를 사용하여 Apache Kafka에서 Apache Kudu로 데이터를 쓰는 방법

# [Arrow](http://arrow.apache.org/)
* [Apache Arrow - Powering Columnar In-Memory Analytics - Arrow is a set of technologies that enable big-data systems to process and move data fast](https://github.com/apache/arrow)
* [Why pandas users should be excited about Apache Arrow](http://wesmckinney.com/blog/pandas-and-apache-arrow/)
* [Feather: A Fast On-Disk Format for Data Frames for R and Python, powered by Apache Arrow](http://blog.cloudera.com/blog/2016/03/feather-a-fast-on-disk-format-for-data-frames-for-r-and-python-powered-by-apache-arrow/)
* [Introducing Apache Arrow: A Fast, Interoperable In-Memory Columnar Data Structure Standard](http://blog.cloudera.com/blog/2016/02/introducing-apache-arrow-a-fast-interoperable-in-memory-columnar-data-structure-standard/)
* [Improving Python and Spark Performance and Interoperability with Apache Arrow](https://www.slideshare.net/julienledem/improving-python-and-spark-performance-and-interoperability-with-apache-arrow)
  * Apache Arrow 프로젝트는 cross-language columnar in-memory alanytics를 구현
  * 대부분의 개발자는 Arrow를 직접 다루지 않지만 PySpark와 같은 여러 가지 작업을 빠르게 처리 가능(하다고 주장)
  * 이 프레젠테이션은 Arrow가 무엇인지, 그리고 그것이 어떻게 속도 향상을 이룰 수 있는지 소개

# Beam (Former [DataFlow](https://wiki.apache.org/incubator/DataflowProposal))
* [The Beam Model : Streams & Tables](https://docs.google.com/document/d/1u-4o_0uj8uKa2SVNPBNxIKfvcJ4t66ecCoU1M2yVoDA/mobilebasic)
  * 스트림 및 테이블을 기반으로 작성된 Apache Beam 모델에 대한 내용
* [bcho.tistory.com/search/dataflow](http://bcho.tistory.com/search/dataflow)
* [구글 데이타 스트리밍 데이타 분석 플랫폼 dataflow - #1 소개](http://bcho.tistory.com/1123)
* [데이타 스트리밍 분석 플랫폼 Dataflow 개념 잡기 #1/2](http://bcho.tistory.com/1122)
* [데이타 스트리밍 분석 플랫폼 Dataflow 개념 잡기 #2/2](http://bcho.tistory.com/1124)
* [GOOGLE DATA FLOW - Google의 Data Flow 개념 및 프로그래밍 방법](https://jungwoon.github.io/jungwoon.github.io/Google-Data-Flow/)
* [데이타 플로우 #4 개발환경 설정하기](http://bcho.tistory.com/1128)
* [데이타 플로우 #5 프로그래밍 모델의 이해](http://bcho.tistory.com/1129)
* [Face recognition Image Cropping and Filtering notebook](https://github.com/bwcho75/facerecognition/blob/master/Preprocess%2Bface%2Brecognition%2Bdata%2Band%2Bgenerate%2Btraining%2Bdata.ipynb)
  * Apache Beam 기반의 전처리 코드
* [Comparing the Dataflow/Beam and Spark Programming Models](https://cloud.google.com/blog/big-data/2016/02/comparing-the-dataflowbeam-and-spark-programming-models#closeImage)

# [Brooklyn](https://brooklyn.apache.org/)

# [Commons](https://commons.apache.org/)

# Cordova
* [Apache Cordova: after 10 months, I won't be using it anymore](http://geekcoder.org/apache-cordova-after-10-months-i-wont-using-it-anymore/)
* [Cordova 환경 구성 & Git Ignore 설정](http://brantiffy.axisj.com/archives/377)
* [ionic cordova emulate 실행 시 Cannot read property 'replace' of undefined 에러 해결하기](http://www.haruair.com/blog/3962)

# [Crunch](https://crunch.apache.org/)

# [Drill](http://drill.apache.org/)
* [Apache Drill SQL Query Optimization | Whiteboard Walkthrough](https://www.mapr.com/blog/apache-drill-sql-query-optimization-whiteboard-walkthrough)

# Eagle
* [Apache Eagle](https://blogs.apache.org/foundation/entry/the-apache-software-foundation-announces1)

# [Falcon - Simplifying Managing Data Jobs on Hadoop](http://www.slideshare.net/Hadoop_Summit/apache-falcon-simplifying-managing-data-jobs-on-hadoop)

# [Flink](https://flink.apache.org/)
* [Apache Flink Training](http://dataartisans.github.io/flink-training/)
* [Juggling with Bits and Bytes](http://flink.apache.org/news/2015/05/11/Juggling-with-Bits-and-Bytes.html)
* [스사모 테크톡 - Apache Flink 둘러보기](http://www.slideshare.net/sangwookimme/apache-flink-48832827)
* [Off-heap Memory in Apache Flink and the curious JIT compiler](http://flink.apache.org/news/2015/09/16/off-heap-memory.html)
* [Stream Processing with Apache Flink](http://blog.brakmic.com/stream-processing-with-apache-flink/)
* [High-throughput, low-latency, and exactly-once stream processing with Apache Flink](http://data-artisans.com/high-throughput-low-latency-and-exactly-once-stream-processing-with-apache-flink/)
* [Continuous Processing with Apache Flink - Strata London 2016](http://www.slideshare.net/stephanewen1/continuous-processing-with-apache-flink-strata-london-2016)
* Introduction to Flink Streaming
  * [Part 1 : WordCount](http://blog.madhukaraphatak.com/introduction-to-flink-streaming-part-1/)
  * [Part 2 : Discretization of Stream using Window API](http://blog.madhukaraphatak.com/introduction-to-flink-streaming-part-2/)
  * [Part 3 : Running Streaming Applications in Flink Local Mode](http://blog.madhukaraphatak.com/introduction-to-flink-streaming-part-3/)
  * [Part 4 : Understanding Flink's Advanced Stream Processing using Google Cloud Dataflow](http://blog.madhukaraphatak.com/introduction-to-flink-streaming-part-4/)
  * [Part 5 : Window API in Flink](http://blog.madhukaraphatak.com/introduction-to-flink-streaming-part-5/)
  * [Part 6 : Anatomy of Window API](http://blog.madhukaraphatak.com/introduction-to-flink-streaming-part-6/)
  * [Part 7 : Implementing Session Windows using Custom Trigger](http://blog.madhukaraphatak.com/introduction-to-flink-streaming-part-7/)
  * [Part 8 : Understanding Time in Flink Streaming](http://blog.madhukaraphatak.com/introduction-to-flink-streaming-part-8/)
  * [Part 9 : Event Time in Flink](http://blog.madhukaraphatak.com/introduction-to-flink-streaming-part-9/)
  * [Part 10 : Meetup Talk](http://blog.madhukaraphatak.com/introduction-to-flink-streaming-part-10/)
  * [Introduction to Flink Streaming](https://www.slideshare.net/datamantra/introduction-to-flink-streaming)
  * [Flink Examples](https://github.com/phatak-dev/flink-examples)
* [A Deep Dive into Rescalable State in Apache Flink](http://flink.apache.org/features/2017/07/04/flink-rescalable-state.html)
  * 체크 포인트 기능을 사용하여 작업을 조정 (예 : 병렬 처리를 늘리거나 줄이기)하는 방법에 대해 설명
* [Stream Processing with Apache Flink and DC/OS](https://mesosphere.com/blog/stream-processing-apache-flink/)
  * DC/OS를 사용하여 Mesos에서 Apache Flink 스트리밍 작업을 실행하는 방법에 대해 소개
* [StreamING Machine Learning Models: How ING Adds Fraud Detection Models at Runtime with Apache Flink®](https://data-artisans.com/blog/real-time-fraud-detection-ing-bank-apache-flink)
  * ING 생명이 리스크 분석 엔진으로 Apache Flink를 어떻게 사용하는지 설명
  * Apache Spark, Knime 및 Apache Zeppelin을 일괄 처리 모델로 사용하지만 실시간 구성 요소는 Flink를 사용
* [PREDICTIVE MAINTENANCE WITH APACHE FLINK](https://berlin.flink-forward.org/kb_sessions/predictive-maintenance-with-apache-flink/)
  * Keras로 만든 time-series prediction model을 Flink와 연동한 이야기
  * python deep learning library(tensorflow, keras)를 이용해서 만든 모델을 JVM에서 어떻게 사용하는지
  * Apache Spark에 비해서 Apache Flink가 가지는 장점에는 어떤 것들이 있는지
* [Complex Event Processing with Flink: An Update on the State of Flink CEP](https://data-artisans.com/blog/complex-event-processing-flink-cep-update)
  * Flink는 이벤트 패턴을 감지하는 고급 API를 제공하여 복잡한 이벤트 처리를 지원
  * API에 대한 개요와 온라인 소매 업체의 선적 추적에 대한 예제
* [An Overview of End-to-End Exactly-Once Processing in Apache Flink® (with Apache Kafka, too!)](https://data-artisans.com/blog/end-to-end-exactly-once-processing-apache-flink-apache-kafka)

# [Geode - an open source, distributed, in-memory database for scale-out applications](http://geode.incubator.apache.org/)
* [Apache Geode Lab](https://github.com/Pivotal-Open-Source-Hub/StockInference-Spark/blob/master/Geode.md)

# [Goblin](https://github.com/apache/incubator-gobblin)

# [Hivemall](https://hivemall.incubator.apache.org/)
* [hivemall.incubator.apache.org/userguide/index.html](http://hivemall.incubator.apache.org/userguide/index.html)
* [Scalable machine learning library for Hive/Hadoop](https://github.com/myui/hivemall)
* [Apache Hivemall: Machine Learning Library for Apache Hive/Spark/Pig](http://www.slideshare.net/myui/dots20161029-myui)

# [Ignite](https://ignite.apache.org/features/igniterdd.html) - Spark Shared RDDs
* [Accelerate Apache Spark SQL Queries](https://ignite.apache.org/use-cases/spark/sql-queries.html)
* [Performance Tuning of an Apache Kafka/Spark Streaming System](https://mapr.com/blog/performance-tuning-apache-kafkaspark-streaming-system/)

# [Imapala](http://impala.io/)
* [Apache Impala (Incubating)](http://www.cloudera.com/products/apache-hadoop/impala.html)
* [Contributing to Impala](http://www.slideshare.net/cloudera/contributing-to-impala)
* [The Impala Cookbook](http://www.slideshare.net/cloudera/the-impala-cookbook-42530186)
* [What’s Next for Impala: More Reliability, Usability, and Performance at Even Greater Scale](http://blog.cloudera.com/blog/2015/07/whats-next-for-impala-more-reliability-usability-and-performance-at-even-greater-scale/)
* [How-to: Prepare Unstructured Data in Impala for Analysis](http://blog.cloudera.com/blog/2015/09/how-to-prepare-unstructured-data-in-impala-for-analysis/)
* [New SQL Benchmarks: Apache Impala (incubating) Uniquely Delivers Analytic Database Performance](http://blog.cloudera.com/blog/2016/02/new-sql-benchmarks-apache-impala-incubating-2-3-uniquely-delivers-analytic-database-performance/)
* [Announcing hs2client, A Fast New C++ / Python Thrift Client for Impala and Hive](http://blog.cloudera.com/blog/2016/06/announcing-hs2client-a-fast-new-c-python-thrift-client-for-impala-and-hive/)
* [Build a Prediction Engine Using Spark, Kudu, and Impala](https://dzone.com/articles/how-to-build-a-prediction-engine-using-spark-kudu)
* [Visualize your massive data with Impala and Redash](https://blog.chezo.uno/visualize-your-massive-data-with-impala-and-re-dash-afe31133c644)
* [Latest Impala Cookbook](http://blog.cloudera.com/blog/2017/02/latest-impala-cookbook/)
* [Ibis on Impala: Python at Scale for Data Science](http://blog.cloudera.com/blog/2015/07/ibis-on-impala-python-at-scale-for-data-science/)
* [SQL-on-Hadoop: Impala vs Drill](https://www.rittmanmead.com/blog/2017/04/sql-on-hadoop-impala-vs-drill/)
  * Apache Impala와 Apach Drill의 주요 구성 요소와 쿼리 처리 메커니즘에 대해 소개
* [Apache Impala Leads Traditional Analytic Database](http://blog.cloudera.com/blog/2017/04/apache-impala-leads-traditional-analytic-database-april-25th/)
  * Live, Spark, Presto와 TPC-DS 밴치마크 비교
* [How to read Impala query plan and profile? Part 1 and 2](https://www.cloudera.com/developers/featured-video.html)
* [Faster Performance for Selective Queries](http://blog.cloudera.com/blog/2017/12/faster-performance-for-selective-queries/)
* [Performance Optimizations in Apache Impala](https://www.slideshare.net/cloudera/performance-of-apache-impala)
  * 쿼리 최적화, 정렬 스캔(ordering scan & Top-N), 조인 패턴 및 이상적인 조인 유형 및 조인 순서 결정, 해시 조인, 집계을 위한 LLVM codegen, 런타임 블룸필터
* [Benchmarking Impala on Kudu vs Parquet](http://boristyukin.com/benchmarking-apache-kudu-vs-apache-impala/)

# [Jena](http://jena.apache.org)

# [Kafka](http://kafka.apache.org/)
* [practice - Kafka on Python](https://hyunjun.github.io/kafka-on-python/)
* [kafka-console-consumer.sh](http://documentation.kamanja.org/command-ref/kafka-console-consumer.html)
* [Kafka - kafka-console-consumer](https://gerardnico.com/wiki/dit/kafka/kafka-console-consumer)
* [KAFKA TUTORIAL: USING KAFKA FROM THE COMMAND LINE](http://cloudurable.com/blog/kafka-tutorial-kafka-from-command-line/index.html)
* [Kafka frequent commands](https://gist.github.com/vkroz/05136cefdbb4fa61296993db17e1ae3f)
* [Kafka in a Nutshell](http://sookocheff.com/post/kafka/kafka-in-a-nutshell/)
* [Docker Quick Start](https://docs.confluent.io/current/installation/docker/docs/quickstart.html)
* [hub.docker.com/r/sheepkiller/kafka-manager](https://hub.docker.com/r/sheepkiller/kafka-manager/)
* [Using Apache Kafka Docker](https://howtoprogram.xyz/2016/07/21/using-apache-kafka-docker/)
* [Kafka Docker - Run multiple Kafka brokers in Docker](https://wurstmeister.github.io/kafka-docker/)
* [HANDS-FREE KAFKA REPLICATION: A LESSON IN OPERATIONAL SIMPLICITY](http://blog.confluent.io/2015/04/07/hands-free-kafka-replication-a-lesson-in-operational-simplicity/)
* [Bottled Water: Real-time integration of PostgreSQL and Kafka](http://blog.confluent.io/2015/04/23/bottled-water-real-time-integration-of-postgresql-and-kafka/)
* [Apache Kafka, Samza, and the Unix Philosophy of Distributed Data](http://www.confluent.io/blog/apache-kafka-samza-and-the-unix-philosophy-of-distributed-data)
* [Apache Kafka: Case of Large Messages, Many Partitions, Few Consumers](https://olnrao.wordpress.com/2015/03/24/apache-kafka-case-of-large-messages-many-partitions-few-consumers/)
* [Distributed Consensus Reloaded: Apache ZooKeeper and Replication in Apache Kafka](http://www.confluent.io/blog/distributed-consensus-reloaded-apache-zookeeper-and-replication-in-kafka)
* [From Kafka to ZeroMQ for real-time log aggregation](http://tomasz.janczuk.org/2015/09/from-kafka-to-zeromq-for-log-aggregation.html)
* [SQL on Kafka](https://www.pipelinedb.com/blog/sql-on-kafka)
* [Kafka at HubSpot: Critical Consumer Metrics](http://product.hubspot.com/blog/kafka-at-hubspot-part-1-critical-consumer-metrics)
* [Bottled Water: Real-time integration of PostgreSQL and Kafka](http://www.confluent.io/blog/bottled-water-real-time-integration-of-postgresql-and-kafka/)
* [빅데이터 윤활유 '아파치 카프카', 왜 주목받나](http://www.ciokorea.com/news/27214)
* [Flafka: Apache Flume Meets Apache Kafka for Event Processing](http://blog.cloudera.com/blog/2014/11/flafka-apache-flume-meets-apache-kafka-for-event-processing/)
* [Why I am not a fan of Apache Kafka](https://gist.github.com/markrendle/26e423b6597685757732)
* [주니어 개발자의 storm kafka 시작하기](http://blog.embian.com/m/post/108)
* [What’s New in Cloudera’s Distribution of Apache Kafka?](http://blog.cloudera.com/blog/2016/02/whats-new-in-clouderas-distribution-of-apache-kafka/)
* [Apache Kafka 성능 테스트](http://blog.embian.com/19)
* [Using Golang and JSON for Kafka Consumption With High Throughput](https://medium.com/the-hoard/using-golang-and-json-for-kafka-consumption-with-high-throughput-4cae28e08f90)
* [대용량 스트리밍 데이터 실시간 분석](http://d2.naver.com/helloworld/7731491)
* [Monitoring Kafka performance metrics](https://www.datadoghq.com/blog/monitoring-kafka-performance-metrics/)
* [Just Enough Kafka for the Elastic Stack, Part 1](https://www.elastic.co/blog/just-enough-kafka-for-the-elastic-stack-part1)
* [How to Monitor Kafka](https://blog.serverdensity.com/how-to-monitor-kafka/)
* [kafka-statsd-metrics2](https://github.com/airbnb/kafka-statsd-metrics2)
* [Kafka New Producer API를 활용한 유실 없는 비동기 데이터 전송](http://readme.skplanet.com/?p=13042)
* [Kafka 0.9 Consumer 클라이언트 소개](http://www.popit.kr/kafka-0-9-consumer-%ED%81%B4%EB%9D%BC%EC%9D%B4%EC%96%B8%ED%8A%B8-%EC%86%8C%EA%B0%9C/)
* [Presto SQL을 이용하여 Kafka topic 데이터 조회하기](http://www.popit.kr/presto-sql%EC%9D%84-%EC%9D%B4%EC%9A%A9%ED%95%98%EC%97%AC-kafka-topic-%EB%8D%B0%EC%9D%B4%ED%84%B0-%EC%A1%B0%ED%9A%8C%ED%95%98%EA%B8%B0/)
* [Presto Kafka connector 개선 실패기](http://www.popit.kr/presto-kafka-connector-%EA%B0%9C%EC%84%A0-%EC%8B%A4%ED%8C%A8%EA%B8%B0/)
* [New in Cloudera Enterprise 5.8: Flafka Improvements for Real-Time Data Ingest](http://blog.cloudera.com/blog/2016/08/new-in-cloudera-enterprise-5-8-flafka-improvements-for-real-time-data-ingest/)
* [Kafka Python client 성능 테스트](http://www.popit.kr/kafka-python-client-%EC%84%B1%EB%8A%A5-%ED%85%8C%EC%8A%A4%ED%8A%B8/)
* [MONITORING APACHE KAFKA WITH GRAFANA / INFLUXDB VIA JMX](https://softwaremill.com/monitoring-apache-kafka-with-influxdb-grafana/)
* [Understanding of Apache Kafka – Part.1](http://bitnine.net/blog-computing/understanding-of-apache-kafka-part-1/)
* [From Big Data to Fast Data in Four Weeks or How Reactive Programming is Changing the World – Part 1](https://www.paypal-engineering.com/2016/11/08/from-big-data-to-fast-data-in-four-weeks-or-how-reactive-programming-is-changing-the-world-part-1/)
* [Apache Kafka, Data Pipelines, and Functional Reactive Programming with Node.js](https://blog.heroku.com/kafka-data-pipelines-frp-node)
* [Building/Runn­i­ng Netflix's Data Pipeline using Apache Kafka](https://www.meetflix.org/tldr/57fc672f25fff9338f1dfc9c/view)
* [코드 한줄 없이 서비스 Dashboard 만들기(1)](http://www.popit.kr/%EC%BD%94%EB%93%9C-%ED%95%9C%EC%A4%84-%EC%97%86%EC%9D%B4-%EC%84%9C%EB%B9%84%EC%8A%A4-dashboard-%EB%A7%8C%EB%93%A4%EA%B8%B0-1/)
* [코드 한줄 없이 서비스 Dashboard 만들기(2)](http://www.popit.kr/%EC%BD%94%EB%93%9C-%ED%95%9C%EC%A4%84-%EC%97%86%EC%9D%B4-%EC%84%9C%EB%B9%84%EC%8A%A4-dashboard-%EB%A7%8C%EB%93%A4%EA%B8%B02/)
* [Kafka 운영자가 말하는 처음 접하는 Kafka](http://www.popit.kr/kafka-%EC%9A%B4%EC%98%81%EC%9E%90%EA%B0%80-%EB%A7%90%ED%95%98%EB%8A%94-%EC%B2%98%EC%9D%8C-%EC%A0%91%ED%95%98%EB%8A%94-kafka/)
* [Kafka 운영자가 말하는 Kafka Consumer Group](http://www.popit.kr/kafka-consumer-group/)
* [Kafka 운영자가 말하는 Producer ACKS](http://www.popit.kr/kafka-%EC%9A%B4%EC%98%81%EC%9E%90%EA%B0%80-%EB%A7%90%ED%95%98%EB%8A%94-producer-acks/)
* [카프카 운영자가 말하는 카프카 서버 실전 로그 분석](http://www.popit.kr/%EC%B9%B4%ED%94%84%EC%B9%B4-%EC%9A%B4%EC%98%81%EC%9E%90%EA%B0%80-%EB%A7%90%ED%95%98%EB%8A%94-%EC%B9%B4%ED%94%84%EC%B9%B4-%EC%84%9C%EB%B2%84-%EC%8B%A4%EC%A0%84-%EB%A1%9C%EA%B7%B8-%EB%B6%84%EC%84%9D/)
* [Kafka 운영자가 말하는 TIP](http://www.popit.kr/kafka-%EC%9A%B4%EC%98%81%EC%9E%90%EA%B0%80-%EB%A7%90%ED%95%98%EB%8A%94-tip/)
* [Kafka Summit New York](https://kafka-summit.org/kafka-summit-ny/schedule/)
* [The First Annual State of Apache Kafka Client Use Survey](https://www.confluent.io/blog/first-annual-state-apache-kafka-client-use-survey/) Kafka와 함께 어떤 언어를 많이 사용하는지와 이유
* [Splunking Kafka with Kafka Connect](https://lilgreenwein.com/2017/02/16/splunking-kafka-with-kafka-connect/)
  * Kafka에서 Splunk로 데이터를 전송하기 위한 새로운 Kafka Connect 플러그인을 설명(아키텍처 및 디자인 선택 포함)
  * Kafka Connect를 설정하여 Kafka topic을 Splunk Heavy Forwarder로 데이터를 스트리밍하는 튜토리얼 포함
* [trivup - Trivially Up a cluster of applications](https://github.com/edenhill/trivup)
  * 프로그래밍 방식으로 카프카 클러스터를 구축하고 해체하는 도구. 클라이언트 응용 프로그램에 대한 Kafka의 SSL 인증 및 암호화 지원
* [Benchmarking Kafka Performance Part 1: Write Throughpu](https://hackernoon.com/benchmarking-kafka-performance-part-1-write-throughput-7c7a76ab7db1)
* [Securing the Confluent Schema Registry for Apache Kafaka](https://www.confluent.io/blog/securing-confluent-schema-registry-apache-kafka/)
  * Confluent Schema Registry를 보호하고 ZooKeeper 및 Kafka 클러스터 보안 연결하도록 구성하는 방법 소개
* **[Apache Kafka지도 시간](http://www.w3ii.com/ko/apache_kafka/default.html)**
* [Exactly-once Support in Apache Kafka](https://medium.com/@jaykreps/exactly-once-support-in-apache-kafka-55e1fdd0a35f)
* [Exactly-once Semantics are Possible: Here’s How Kafka Does it](https://www.confluent.io/blog/exactly-once-semantics-are-possible-heres-how-apache-kafka-does-it/)
* [Kafka 운영자가 말하는 Topic Replication](http://www.popit.kr/kafka-%EC%9A%B4%EC%98%81%EC%9E%90%EA%B0%80-%EB%A7%90%ED%95%98%EB%8A%94-topic-replication/)
* [Upgrading Apache Kafka Clients Just Got Easier](https://www.confluent.io/blog/upgrading-apache-kafka-clients-just-got-easier/)
  * 최신 버전에 Kafka 클라이언트의 순방향/역방향 호환성 추가
  * 이 기능을 사용하는 방법 및 브로커와 다른 버전의 클라이언트를 사용할 경우에 대해 설명
* The Simplest Useful Kafka Connect Data Pipeline In The World … or Thereabouts
  * [Part 1](https://www.confluent.io/blog/simplest-useful-kafka-connect-data-pipeline-world-thereabouts-part-1/)
    * RDBMS (이 경우 MySQL)에서 변경 데이터 캡처를 위해 Apache Kafka Connect를 사용하는 방법을 예제를 통해 설명
  * [Part 2](https://www.confluent.io/blog/blogthe-simplest-useful-kafka-connect-data-pipeline-in-the-world-or-thereabouts-part-2/)
  * [Part 3](https://www.confluent.io/blog/simplest-useful-kafka-connect-data-pipeline-world-thereabouts-part-3/)
* [Cruise-control - the first of its kind to fully automate the dynamic workload rebalance and self-healing of a kafka cluster. It provides great value to Kafka users by simplifying the operation of Kafka clusters](https://github.com/linkedin/cruise-control)
* [Monitoring Kafka Consumer Offsets](https://blog.godatadriven.com/monitoring-kafka-consumer-lag)
  * Kafka consumer offset을 간단하게 모니터링하는 방법
  * Kafka consumer offset을 HTTP를 통해 내보내고 Prometheus를 사용하여 Grafana로 시각화
* [aiokafka - asyncio client for kafka http://aiokafka.readthedocs.io/](https://github.com/aio-libs/aiokafka)
* [How to Build and Deploy Scalable Machine Learning in Production with Apache Kafka](https://www.confluent.io/blog/build-deploy-scalable-machine-learning-production-apache-kafka/)
  * 미션 크리티컬한 실시간 애플리케이션에서 중앙집중적이고 확장가능한 아키텍처를 어떻게 만들지에 대한 유스케이스에 대해 논의
* KSQL
  * [Introducing KSQL: Open Source Streaming SQL for Apache Kafka](https://www.confluent.io/blog/ksql-open-source-streaming-sql-for-apache-kafka/)
    * spark streaming의 대체?
    * Apache Kafka에서 SQL을 사용할 수 있는 인터페이스를 제공
  * [Getting Started Analyzing Twitter Data in Apache Kafka through KSQL](https://www.confluent.io/blog/using-ksql-to-analyse-query-and-transform-data-in-kafka)
    * 트위터의 스트리밍 데이터를 KSQL의 술어(predicate)로 필터링하고 시간당 사용자당 트윗 수를 계산하는 등 집계를 작성하는 예제
  * [KSQL: Streaming SQL for Apache Kafka](https://www.rittmanmead.com/blog/2017/10/ksql-streaming-sql-for-apache-kafka/)
  * [Taking KSQL for a Spin Using Real-time Device Data](https://www.rittmanmead.com/blog/2017/11/taking-ksql-for-a-spin-using-real-time-device-data/)
    * KSQL을 사용하여 간단한 스트리밍 프로그램을 보여주는 포스트
    * 입력이 드라이빙 게임 핸들의 디지털 센서 데이터 스트림
  * [Building a Microservices Ecosystem with Kafka Streams and KSQL](https://www.confluent.io/blog/building-a-microservices-ecosystem-with-kafka-streams-and-ksql/)
    * 카프카 스트림을 이용한 동기식 트랜잭션 시스템을 구축하는 예제
    * 사이드카 패턴을 통해 비 JVM 언어에 대해 패턴을 구현하기 위해 KSQL을 사용하는 개념 언급
  * [KSQL January release: Streaming SQL for Apache Kafka](https://www.confluent.io/blog/ksql-january-release-streaming-sql-apache-kafka/)
  * [How to Write a User Defined Function (UDF) for KSQL](https://www.confluent.io/blog/write-user-defined-function-udf-ksql/)
    * 아직 사용자 정의 함수(UDFs)의 런타임 구성을 지원하지 않지만 사용자 함수를 작성하고 빌드 가능
  * [KSQL in Action: Real-Time Streaming ETL from Oracle Transactional Data](https://www.confluent.io/blog/ksql-in-action-real-time-streaming-etl-from-oracle-transactional-data)
* [How To Install Apache Kafka on Ubuntu 14.04](https://www.digitalocean.com/community/tutorials/how-to-install-apache-kafka-on-ubuntu-14-04)
* [Benchmarking Message Queue Latency](https://bravenewgeek.com/benchmarking-message-queue-latency/)
* [How Apache Kafka Inspired Our Platform Events Architecture](https://engineering.salesforce.com/how-apache-kafka-inspired-our-platform-events-architecture-2f351fe4cf63)

## Stream
* [Kafka Streams examples](https://github.com/confluentinc/kafka-streams-examples)
* [REACTIVE STREAMS FOR APACHE KAFKA](https://softwaremill.com/reactive-kafka/)
* [This is a Kafka-Storm-Esper example on vagrant](https://github.com/doohee323/tzstorm)
  1. kafka를 사용할 때 Producer.send 해서 stream을 전달하던데, legacy시스템에서 별도의 코딩을 통해서 구현해야 하는 것인지 => kafka를 사용할 때 보통 producer, consumer를 구현한다. kafka - storm을 사용할 때 kafkaspout는 consumer 역할은 한다.
  2. KafkaSpout에서 생성된 stream이 storm의 Bolt로 들어올 때 어떻게 디버깅이 가능한 지 => 원격 디버깅은 없고 -Dstorm.log.dir를 통한 로그파일로 디버깅한다.
  3. bolt로 넘어온 중복된 stream을 어떻게 unique한 데이터로 처리 가능한 지 => unique한 데이터 처리를 위해서 trident를 사용하며, trident는 storm의 구현을 지원하는 (aggregation 등) 역할을 한다. -> esper로 group by 등의 쿼리문을 만들 수 있는데 trident와 역할 충돌이 있지 않을까 싶지만, trident를 통해 unique한 데이터를 받아 esper로 쿼리문을 돌릴 수 있지 않을까 싶다.
  4. kafka 대신에 zmq로 연동할 때 예상되는 문제점이 있는지. zmq와 kafka 모두 큐 역할을 하므로 특별한 이유가 없다면 zmqspout를 활용하는 것이 좋겠다.
* [stream-reactor Streaming reference architecture built around Kafka. http://datamountaineer.com/2016/01/12/streamliner/](https://github.com/datamountaineer/stream-reactor)
* [Distributed, Real-time Joins and Aggregations on User Activity Events using Kafka Streams](http://www.confluent.io/blog/distributed-real-time-joins-and-aggregations-on-user-activity-events-using-kafka-streams)
* [Tweeter: Processing Tweets with Kafka Streams](https://www.madewithtea.com/processing-tweets-with-kafka-streams.html)
* [내부 데이터 파이프라인에 Kafka Streams 적용하기](https://engineering.linecorp.com/ko/blog/detail/80)
  * [Line: Applying Kafka Streams for internal message delivery pipeline](https://engineering.linecorp.com/en/blog/detail/80)
* [Quick Recipe for #Kafka Streams in #Clojure](https://dataissexy.wordpress.com/2016/12/06/quick-recipe-for-kafka-streams-in-clojure/)
* [Perfecting Lambda Architecture with Oracle Data Integrator (and Kafka / MapR Streams)](https://www.mapr.com/blog/perfecting-lambda-architecture-oracle-data-integrator-and-kafka-mapr-streams)
  * MySQL 데이터베이스의 변경 내용을 스트림으로 캡처하기 위해 Oracle Data Integrator, Apache Kafka / MapR Stream를 구성하는 과정
* [Streaming databases in realtime with MySQL, Debezium, and Kafka](https://wecode.wepay.com/posts/streaming-databases-in-realtime-with-mysql-debezium-kafka)
  * WePay에서 Debezium을 사용하여 Kafka로 데이터를 스트리밍하는 MySQL용 데이터 캡처 솔루션을 사용하는 것에 대한 기사
* [Kafka + Spark-Streaming with Python으로 실시간 분석시스템 만들기](http://hellowuniverse.com/2017/04/26/kafka-spark-streaming-with-python%EC%9C%BC%EB%A1%9C-%EC%8B%A4%EC%8B%9C%EA%B0%84-%EB%B6%84%EC%84%9D%EC%8B%9C%EC%8A%A4%ED%85%9C-%EB%A7%8C%EB%93%A4%EA%B8%B0/)
* [Kafka + Spark-Streaming with Python으로 실시간 분석시스템 만들기(2)](http://hellowuniverse.com/2017/05/15/kafka-spark-streaming-with-python%EC%9C%BC%EB%A1%9C-%EC%8B%A4%EC%8B%9C%EA%B0%84-%EB%B6%84%EC%84%9D%EC%8B%9C%EC%8A%A4%ED%85%9C-%EB%A7%8C%EB%93%A4%EA%B8%B02/)
* [Reading data securely from Apache Kafka to Apache Spark](http://blog.cloudera.com/blog/2017/05/reading-data-securely-from-apache-kafka-to-apache-spark/)
  * Cloudera에서 최근 Kafka와 연계된 Spark 작업에 암호화 및 권한 부여를 제공하기 위해 Apache Kafka, Apache Spark, Apache Ranger를 통합
  * 이를 어떻게 구현하고 왜 이런 설계를 하게되었는지 설명
* [Kafka Connect vs StreamSets: advantages and disadvantages?](https://www.linkedin.com/pulse/kafka-connect-vs-streamsets-advantages-disadvantages-slim-baltagi)
  * Kafka Connect 및 StreamSets 데이터 수집기 비교 설명
* [Evolving Avro Schemas with Apache Kafka and StreamSets Data Collector](https://streamsets.com/blog/evolving-avro-schemas-apache-kafka-streamsets-data-collector/)
  * Streamsets의 Dataflow Performance Blog에 올라온 내용
  * Avro의 스키마 버번을 저장하기 위해 Confluent Schema Registry의 동기화에 대해 설명
  * Streamset의 데이터 수집기 도구를 사용하여 schema-aware producer를 사용하여 데이터를 serialize/deserialize 하는 방법 설명
* [Performance Tuning of an Apache Kafka/Spark Streaming System - Telecom Case Study](https://mapr.com/blog/performance-tuning-kafka-spark-streaming-telecom/)
  * Apache Kafka, Spark Streaming 및 Apache Ignite (RDD의 캐싱)와 관련된 실제 응용 프로그램의 성능 튜닝
  * Kafka 파티션 수 증가, RPC 시간 초과 설정 수정, Spark 및 Ignite 메모리 모두 조정, 일괄 처리 간격 수정 등
* [Build Services on a Backbone of Events](https://www.confluent.io/blog/build-services-backbone-events/)
  * Apache Kafka가 단순히 빠른 ETL보다 더 혁신적이고 좋다고 주장
  * 스트리밍, 응용 프로그램, 데이터베이스 간의 통합, ETL (중앙 집중식 모노리스가 아닌) 배포, 규모 및 안정성 등 Kafka가 제공하는 장점을 강조
* [High Performance Kafka Consumer for Spark Streaming. Now Support Spark 2.0 and Kafka 0.10](https://github.com/dibbhatt/kafka-spark-consumer)
* [Recent Evolution of Zero Data Loss Guarantee in Spark Streaming With Kafka](http://getindata.com/blog/post/recent-evolution-of-zero-data-loss-guarantee-in-spark-streaming-with-kafka/)
* [Spark Streaming + Kafka Integration Guide (Kafka broker version 0.10.0 or higher)](https://spark.apache.org/docs/latest/streaming-kafka-0-10-integration.html)
* [Getting Started with the Kafka Streams API using Confluent Docker Images](https://www.confluent.io/blog/getting-started-with-the-kafka-streams-api-using-confluent-docker-image/)
* [Real-time Financial Alerts at Rabobank with Apache Kafka’s Streams API](https://www.confluent.io/blog/real-time-financial-alerts-rabobank-apache-kafkas-streams-api/)
  * Rabobank가 메인 프레임에서 Apache Kafka(다중 데이터 센터 배포 및 Kafka Streams로 구축)로 고객 알림 시스템을 이동한 사례에 대해 설명
* [Real-Time Anomaly Detection Streaming Microservices with H2O and MapR – Part 1: Architecture](https://mapr.com/blog/real-time-anomaly-detection-1/)
  * IOT 센서 데이터를 스트리밍하여 비정상 상태를 감지하는 아키텍처에 대해 소개
* [Streaming Kafka Messages to MySQL Database](https://www.toadworld.com/platforms/oracle/w/wiki/11647.streaming-kafka-messages-to-mysql-database) flume과의 조합
* [Integrating Kafka and Spark Streaming: Code Examples and State of the Game](http://www.michael-noll.com/blog/2014/10/01/kafka-spark-streaming-integration-example-tutorial/)
* [Spark Streaming with Kafka and Cassandra](http://helenaedelson.com/?p=991)
* [Ranking Websites in Real-time with Apache Kafka’s Streams API](https://www.confluent.io/blog/ranking-websites-real-time-apache-kafkas-streams-api/)
  * 유럽 최대의 온라인 패션 소매 업체인 Zalando에서 Apache Kafka를 사용하여 패션 웹 사이트의 정보를 색인하고 순위를 매기는 방법에 대해 소개
  * 이 시스템은 HITS (Hyperlink Induced Topic Search) 알고리즘을 사용하며 Kafka 스트림이 기반
* [Using Kafka Streams API for predictive budgeting](https://medium.com/@Pinterest_Engineering/using-kafka-streams-api-for-predictive-budgeting-9f58d206c996)
* [lenses - a Streaming Data Management Platform for Apache Kafka](http://www.landoop.com/kafka-lenses/)
  * [How to explore data in Kafka topics with Lenses - part 1](http://www.landoop.com/blog/2017/11/lenses-how-to-view-kafka-topics-data/)
  * [stream-reactor - Streaming reference architecture for ETL with Kafka and Kafka-Connect. You can find more on http://landoop.com on how we provide a unified solution to manage your connectors, most advanced SQL engine for Kafka and Kafka Streams, cluster monitoring and alerting, and more http://www.landoop.com/kafka/connectors/](https://github.com/Landoop/stream-reactor)
* [Kafka & Redis Streams](https://medium.com/@timothy_downs/introduction-to-redis-streams-133f1c375cd3)
* [Enabling Exactly-Once in Kafka Streams](https://www.confluent.io/blog/enabling-exactly-kafka-streams/)
* [Migrating Batch ETL to Stream Processing: A Netflix Case Study with Kafka and Flink](https://www.infoq.com/articles/netflix-migrating-stream-processing)
  * QCon New York 2017에서 Netflix의 스트림 처리 시스템에 대해 소개한 내용을 설명
  * Apache Kafka, Apache Flink, Apache Mesos 등으로 구축
  * 비디오 재생 / 검색 이벤트의 데이터를 분석
  * Netflix가 직면한 도전 과제와 그것에 따라 구현된 전략에 대해서도 설명

# [Kudu](http://kudu.apache.org/)
* [Kudu](http://blog.cloudera.com/blog/2015/09/kudu-new-apache-hadoop-storage-for-fast-analytics-on-fast-data/)
* [getkudu.io](http://getkudu.io/)
* [Kudu: New Hadoop Storage for Fast Analytics on Fast Data](http://www.slideshare.net/cloudera/kudu-new-hadoop-storage-for-fast-analytics-on-fast-data)
* [Apache Kudu as a More Flexible And Reliable Kafka-style Queue](http://blog.rodeo.io/2016/01/24/kudu-as-a-more-flexible-kafka.html)
* [Big Data: current trends & next big thing 'Apache Kudu' - my takeaways from Strata + Hadoop 2016 @San Jose](https://www.linkedin.com/pulse/notes-strata-hadoop-2016-san-jose-shenghu-hugo-yang)
* [#bbuzz 2016: Todd Lipcon - Apache Kudu (incubating): Fast Analytics on Fast Data](https://www.youtube.com/watch?v=z3rApSRXNMw&feature=youtu.be)
* [Build a Prediction Engine Using Spark, Kudu, and Impala](https://dzone.com/articles/how-to-build-a-prediction-engine-using-spark-kudu)
* [Creating a Post-Lambda World with Apache Kudu](http://vision.cloudera.com/creating-a-post-lambda-world-with-apache-kudu/)
* [Up and running with Apache Spark on Apache Kudu](http://blog.cloudera.com/blog/2017/02/up-and-running-with-apache-spark-on-apache-kudu/)
* [Apache Kudu 1.3.0 was released](http://kudu.apache.org/releases/1.3.0/docs/release_notes.html)
  * Apache Kudu 1.3.0 릴리즈
  * Kerberos 인증, TLS를 사용한 암호화 전송, coarse-grained authorization 등 새로운 기능 추가
  * LZ4 압축으로 전환하는 등 몇 가지 최적화 기능 포함
* [Apache Kudu Read & Write Paths](http://blog.cloudera.com/blog/2017/04/apache-kudu-read-write-paths/)
* kudu-master clustering

  ```
  kudu-master \ 
    --master_addresses=172.23.30.101,172.23.30.102,172.23.30.103 \ 
    --fs_data_dirs=/data1/kudu/master/data \ 
    --fs_wal_dir=/data1/kudu/master/wal \
    --log_dir=/opt/log/kudu \
    --raft_get_node_instance_timeout_ms=60000
  ```
  * 위와 같이 3대에 띄우면, /data1/kudu/master/data 하위에 consensus를 맞추고 리더가 선출된 후에 별도의 000000000000000000 파일을 생성
  * 성공적으로 띄워지고 난 후로는 클러스터 노드가 깨져도 다시 띄울때 오류가 발생하지 않음
  * 오류 발생하였을 때는, /data1/kudu/master/data 와 /data1/kudu/master/wal 디렉토리 삭제후 다시 raft_get_node_instance_timeout_ms 내에 클러스터를 이루는 IP에 프로세스가 실행되도록 하면 됨
* [Low latency high throughput streaming using Apache Apex and Apache Kudu](https://www.slideshare.net/Hadoop_Summit/low-latency-high-throughput-streaming-using-apache-apex-and-apache-kudu)
  * Apache Kudu와 Apache Apex를 이용한 고성능 스트리밍처리 방식에 대해 설명
* [A brave new world in mutable big data relational storage (Strata NYC 2017)](https://www.slideshare.net/ToddLipcon/a-brave-new-world-in-mutable-big-data-relational-storage-strata-nyc-2017)

# [Kylin](http://kylin.apache.org/) Extreme OLAP Engine for Big Data
* **[빅데이터 다차원 분석 플랫폼, Kylin](http://d2.naver.com/helloworld/1057065)**
* [Apache Kylin 2.2.0 is released](https://kylin.apache.org/docs21/release_notes.html)
  * Apache Ranger를 사용하여 테이블 레벨에서 ACL을 관리하는 기능 등이 탑재
* [Using Hue to interact with Apache Kylin in your cluster or on AWS](http://gethue.com/using-hue-to-interact-with-apache-kylin/) Hue에서 JDBC 드라이버를 통해 Apache Kylin을 조회할 수 있는 방법을 설명합니다. AWS EMR 포함

* [Logging](https://logging.apache.org)

# [Mesos](http://mesos.apache.org/)
* [Advanced Mesos Course](http://open.mesosphere.com/intro-course/)
* [Spark(1.2.1 -> 1.3.1) 을 위한 Mesos(0.18 -> 0.22.rc) - Upgrade](http://hoondongkim.blogspot.kr/2015/05/spark121-131-mesos018-021-upgrade.html)
* [mesos, omega, borg: a survey](http://www.umbrant.com/blog/2015/mesos_omega_borg_survey.html)
* [Mesos: A Platform for Fine-Grained Resource Sharing in the Data Center](http://people.csail.mit.edu/matei/papers/2011/nsdi_mesos.pdf)
* [minmesos - Testing infrastructure for Mesos frameworks](http://minimesos.org/)
* [메소스(mesos) 공부](http://knight76.tistory.com/entry/%EB%A9%94%EC%86%8C%EC%8A%A4-%EA%B0%84%EB%8B%A8-%EC%A0%95%EB%A6%AC)

# [Metron](http://metron.apache.org) 보안에 포커스를 둔 분석 시스템

# [Nifi](https://nifi.apache.org/) Apache nifi is an easy to use, powerful, and reliable system to process and distribute data
* [NiFi를 이용한 빅데이터 플랫폼 개선](http://www.popit.kr/bigdata-platform-based-on-nifi/)
* [NSA의 Dataflow 엔진 Apache NiFi 소개와 설치](http://www.popit.kr/apache-nifi-overview-and-install/)
* [NiFi vs Falcon vs Oozie](https://www.linkedin.com/pulse/nifi-vs-falcon-oozie-birender-saini)
* [NiFi 소개 발표 자료](http://www.popit.kr/nifi-%EC%86%8C%EA%B0%9C-%EB%B0%9C%ED%91%9C-%EC%9E%90%EB%A3%8C/)
* [Introduction to Apache NiFi and Storm](https://speakerdeck.com/heartsavior/introduction-to-apache-nifi-and-storm)
* [Apache NiFi 1.x Cheatsheet](https://dzone.com/articles/apache-nifi-10-cheatsheet)
  * Apache NiFi에는 많은 Processor가 있어 어떤 Processor를 사용해야 할 지 찾아야 하는 경우가 많은데, 많이 사용하는 Processor를 소개
  * NiFi의 Rest API에 대해서도 설명
* [NiFi User Interface Overview](https://www.youtube.com/watch?v=Y5znvcJ_NWo&feature=share)
* 실시간 Kafka consumer cluster를 구성하니
  * 구동속도 빠르고, 모니터링 편하고, 복잡한 transform GUI로 관리하고, partitioning도 알아서 한다는 글을 봤음
  * 간단한 작업에도 적합할까?
* [Apache NiFi 소개 및 Tensorflow 연동](https://www.facebook.com/nextobe1/posts/337425993360069)

# [Nutch](http://nutch.apache.org/)
* [Apache Nutch - 오픈소스 웹 검색 엔진](http://jsonlee.tistory.com/entry/Apache-Nutch-%EC%98%A4%ED%94%88%EC%86%8C%EC%8A%A4-%EC%9B%B9-%EA%B2%80%EC%83%89-%EC%97%94%EC%A7%84)

# [Oozie](http://oozie.apache.org/)
* [How-to: Use the New Apache Oozie Database Migration Tool](http://blog.cloudera.com/blog/2016/11/how-to-use-the-new-apache-oozie-database-migration-tool/)

# [Parquet](https://parquet.apache.org/)
* [Using Apache Parquet at AppNexus](http://blog.cloudera.com/blog/2015/04/using-apache-parquet-at-appnexus/)
* [Dremel made simple with Parquet](https://blog.twitter.com/2013/dremel-made-simple-with-parquet)
* [Benchmarking Apache Parquet: The Allstate Experience](http://blog.cloudera.com/blog/2016/04/benchmarking-apache-parquet-the-allstate-experience/)

# [Pig](http://pig.apache.org/)
* [A Simple Explanation of COGROUP in Apache Pig](http://joshualande.com/cogroup-in-pig/)
* examples
  * [gist.github.com/hyunjun/55f83bfd91e2b1e24f46](https://gist.github.com/hyunjun/55f83bfd91e2b1e24f46)
* [hug number of part files](https://github.com/dsindex/blog/wiki/%5Bpig%5D-hug-number-of-part-files)
* [Hadoop Tutorial: Pig Part 2 -- Joining Data Sets and Other Advanced Topics](http://www.slideshare.net/martyhall/hadoop-tutorial-pig-part-2-joining-data-sets-and-other-advanced-topics)
* [Hadoop Pig Tutorial](https://medium.com/@ananthis740/hadoop-pig-tutorial-7f3b827b25cb)

# [Phoenix](http://phoenix.apache.org/) High performance relational database layer over HBase for low latency applications
* [Apache Phoenix Joins Cloudera Labs](http://blog.cloudera.com/blog/2015/05/apache-phoenix-joins-cloudera-labs/)
* [Apache Phoenix: Use Cases and New Features](http://www.slideshare.net/HBaseCon/apache-phoenix-use-cases-and-new-features)
  * HBase + Phoenix를 활용하여 Timeseries DB로 사용하도록 하는 Argus, ACID Transaction 이 가능케 하는 Apache Tephra, Cost bases Query Optimizer인 Apache Calite 활용 사례 소개
* [The Apache Software Foundation: Column Mapping and Immutable Data Encoding of Apach Phoenix 4.1](https://blogs.apache.org/phoenix/entry/column-mapping-and-immutable-data)
  * Apache Phoenix 4.10 릴리즈
  * 새로운 기능인 컬럼 매핑과 변경 불가 데이터 인코딩 기능을 소개
  * TPC-H benchmark상으로 속도 향상 및 공간 절약 효과가 상당
* [Apache Spark Plugin](https://phoenix.apache.org/phoenix_spark.html)

# [PredictionIO](http://predictionio.incubator.apache.org/)
* [incubator-predictionio - PredictionIO, a machine learning server for developers and ML engineers. Built on Apache Spark, HBase and Spray. http://prediction.io/](https://github.com/apache/incubator-predictionio)

# Pulsar
* Geo-replication in Apache Pulsar
  * [part 1: concepts and features](https://streaml.io/blog/apache-pulsar-geo-replication)
  * [part 2: patterns and practices](https://streaml.io/blog/geo-replication-patterns-practices)
  * Apache Pulsar를 사용하여 cross-data center replication를 수행하는 방법에 대해 설명
  * 복제를 설정하는 데 필요한 명령, 응용 프로그램별로 재정의하는 방법, 모니터링 방법, 복제 대역폭을 제한하는 방법 등에 대해 설명

# [Ranger](http://ranger.apache.org)
* [IT’S MORPHING TIME: APACHE RANGER GRADUATES TO A TOP LEVEL PROJECT – PART 2](https://hortonworks.com/blog/morphing-time-apache-ranger-graduates-top-level-project-part-2/)
  * Apache 탑 레벨 프로젝트로 승격된 Apach Ranger에 대한 Key Feature 소개
  * 속성 기반의 엑세스 제어, 정책 엔진, 하드웨어 관리 모들과 결합할 수 있는 키 관리 서비스 등을 포함
* [INTRODUCING ROW/ COLUMN LEVEL ACCESS CONTROL FOR APACHE SPARK](https://hortonworks.com/blog/row-column-level-control-apache-spark/)
  * Hortonworks에서 Apache Ranger를 통해 Hive 또는 Apark SQL에서 행렬 수준의 데이터 엑세스 및 데이터 마스킹을 지원하는 방법을 간단한 데모와 함께 설명

# [River](https://river.apache.org/)

# Samza
* [REAL-TIME FULL-TEXT SEARCH WITH LUWAK AND SAMZA](http://blog.confluent.io/2015/04/13/real-time-full-text-search-with-luwak-and-samza/)
* [Apache Kafka, Samza, and the Unix Philosophy of Distributed Data](http://www.confluent.io/blog/apache-kafka-samza-and-the-unix-philosophy-of-distributed-data)

# [SINGA](http://singa.apache.org/docs/overview.html) a general distributed deep learning platform for training big deep learning models over large datasets

# Solr
* [gooper.com/검색엔진-solr](http://www.gooper.com/ss/index.php?mid=bigdata&category=270441)

# [Spot](http://spot.incubator.apache.org/) 네트워크 데이터를 분석하여 infosec 위협을 탐지하는데 사용
* [Apache Spot (incubating) and Cloudera on AWS in 60 Minutes](http://blog.cloudera.com/blog/2018/02/apache-spot-incubating-and-cloudera-on-aws-in-60-minutes/)
  * Apache Kafka(처리용), Apache Spark(처리 및 ML 분석용), Apache Hadoop(처리 및 저장용) 등을 기반으로 한 Apache Spot의 아키텍처 소개
  * Spot은 파일 시스템의 변경 사항을 감지하고 이벤트를 발생시키는 Python Watchdog 라이브러리를 사용

# Sqoop
* [An HDFS Tutorial for Data Analysts Stuck With Relational Databases](https://www.datatorrent.com/blog/throughput-latency-and-yahoo/) PostgreSQL to HDFS
* [SQOOP으로 MYSQL 데이터 가져오기](https://jungwoon.github.io/jungwoon.github.io/Sqoop-with-MySQL/)
* [How to Convert Apache Sqoop™ Commands Into StreamSets Data Collector Pipelines](https://streamsets.com/blog/using-streamsets-data-collector-modernize-apache-sqoop/)
  * Streamsets의 Dataflow Performance Blog에 올라온 내용
  * Apache Sqoop을 대체하기 위한 마이그레이션 방법 및 고려 사항에 대해 간단하게 설명

# [SystemML](http://systemml.apache.org/) Apache Spark와 Apache Hadoop을 확장하기 위해 빌드된 machine learning 라이브러리
* [IBM's SystemML Machine Learning - Now Apache SystemML](https://github.com/SparkTC/systemml)
* [The Apache Software Foundation Announces Apache® SystemML™ as a Top-Level Project](https://blogs.apache.org/foundation/entry/the-apache-software-foundation-announces13)

# [Tajo](http://tajo.apache.org/)
* [Introduction to Apache Tajo](http://www.slideshare.net/gruter/introduction-to-apache-tajo)
* [누구나 따라할 수 있는 Tajo 시작하기 : How to install Apache Tajo](http://blrunner.com/101)
* [아즈카반으로 타조 워크플로우 구성하기 : How to schedule Tajo Job using Azkaban](http://blrunner.com/102)
* [Collaborate Apache Tajo + Elasticsearch](https://github.com/gruter/tajo-elasticsearch)
* [아파치 타조(Apache Tajo)를 이용한 코호트(Cohort) 분석](http://blrunner.com/80)
* [아파치 타조 (Apache Tajo) 한글 문서 프로젝트 리소스 및 진행 공유](http://diveintodata.org/2015/01/01/%EC%95%84%ED%8C%8C%EC%B9%98-%ED%83%80%EC%A1%B0-apache-tajo-%ED%95%9C%EA%B8%80-%EB%AC%B8%EC%84%9C-%ED%94%84%EB%A1%9C%EC%A0%9D%ED%8A%B8-%EB%A6%AC%EC%86%8C%EC%8A%A4-%EB%B0%8F-%EC%A7%84%ED%96%89/)
* [Big data analysis with R and Apache Tajo (in Korean)](http://www.slideshare.net/gruter/ruck2015-gruter-public)
* [Tajo Seoul Meetup July 2015 - What's New Tajo 0.11](http://www.slideshare.net/hyunsikchoi/tajo-meetup-0716)
* [Apache Tajo 데스크탑 + Zeppelin 연동 하기](http://jjeong.tistory.com/1031)
* [Expanding Your Data Warehouse with Tajo](http://www.slideshare.net/blrunner/expanding-your-data-warehouse-with-tajo)
* [AWS + Tajo를 이용한 '테라 렉 로그 분석 이야기'](http://www.slideshare.net/zenos2408/aws-tajo)
* [Python 에서 Tajo 사용하기](http://linewalks.com/archives/1085)
* [MelOn 빅데이터 플랫폼과 Tajo 이야기](http://www.slideshare.net/gruter/melon-tajo)

* Thrift
* [Apache Thrift](https://github.com/likejazz/likejazz.github.io/wiki/Apache-Thrift)
* [아파치 쓰리프트의 bool 타입 관련 제한 값](http://knight76.tistory.com/entry/%EC%95%84%ED%8C%8C%EC%B9%98-%EC%93%B0%EB%A6%AC%ED%94%84%ED%8A%B8%EC%9D%98-bool-%ED%83%80%EC%9E%85-%EA%B4%80%EB%A0%A8-%EC%A0%9C%ED%95%9C-%EA%B0%92)

# [Toree](http://toree.apache.org/)

# [UIMA](https://uima.apache.org)

# [WEEX](https://weex.apache.org/) A framework for building Mobile cross-platform UIs

# [Zookeeper](http://zookeeper.apache.org/)
* [Zoom: Reactive Programming with Zookeeper](http://blog.midonet.org/zoom-reactive-programming-zookeeper/)
* [The Discovery of Apache ZooKeeper’s Poison Packet](http://www.pagerduty.com/blog/the-discovery-of-apache-zookeepers-poison-packet/)
* [Mining Zookeeper’s transaction log to track down bugs](https://medium.com/@ivankelly/mining-zookeeper-s-transaction-log-to-track-down-bugs-63b4c653bb6)
* [Apache ZooKeeper Four Letter Words and Security](http://blog.cloudera.com/blog/2017/06/apache-zookeeper-four-letter-words-and-security/)
  * Apache ZooKeeper의 네 글자 단어 지원(4lw)에 대한 간략한 내용
  * 이러한 관리 명령의 경우 정상적인 ZK 포트를 통한 연결과 같이 좋은 보안 솔루션이 없음
  * 다른 방법으로, ZooKeeper는 JMX를 지원하고 3.5.x 릴리스에서는 별도의 포트에 AdminServer를 제공
* [HashiCorp사의 Consul, Consul Template 소개](http://www.giljae.com/2017/07/hashicorp-consul-consul-template_4.html)
